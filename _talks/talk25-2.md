---
name: 'Experiential geosimulation'
speakers:
  - Paul M. Torrens
  - Ryan Kim
  - Kaishuu Shinozaki-Conefrey
categories:
  - Presentation
  - Research
year: 2025
links:
  - name: Paper
    absolute_url: https://doi.org/10.1145/3764921.377014706
    icon: file
---

We introduce experiential geosimulation as a medium for co-exploring embodied behavioral geography, physical locomotion and sensorimotor control, and spatial vision and perception. Methodologically, this convergence is approached through interconnection of high-fidelity geographic automata systems, running in virtual geographic environments within virtual reality head-mounted displays, while spatial telematics and neural activity are collected through eye tracking on a single-board computer and encephalography (EEG) is processed from a scalp-mounted brain-computer interface. Data exchange between these diverse geographic information systems allows for the creation of synthetic simulation scenarios that can evoke realistic locomotion and task behavior from real, physically involved human users. Here, we show that the system also entices people’s realistic neural activity, which can provide insight into users’ experiences as navigation, agency, spatial vision, landmark salience, non-verbal communications, and cognitive where/what reasoning.

